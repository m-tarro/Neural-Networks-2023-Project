{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Necessary imports","metadata":{}},{"cell_type":"code","source":"!pip install -U scikit-learn\n# !pip install bokeh\n\n!pip install tf-models-official\n!pip install -U tensorflow-addons==0.20.0\n# !pip install efficientnet","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:28:22.570491Z","iopub.execute_input":"2023-06-14T19:28:22.570850Z","iopub.status.idle":"2023-06-14T19:29:18.956072Z","shell.execute_reply.started":"2023-06-14T19:28:22.570816Z","shell.execute_reply":"2023-06-14T19:29:18.954995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math, re, os, sys\nimport numpy as np\nimport pandas as pd\nfrom itertools import islice\nfrom matplotlib import pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom tqdm import tqdm\n\n# from bokeh.plotting import figure, show, save\n# from bokeh.models import HoverTool, LinearColorMapper, ColumnDataSource\n# from bokeh.io import output_notebook\n# from bokeh.transform import linear_cmap\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import layers, callbacks\nfrom tensorflow_models.vision import augment\n# import efficientnet.tfkeras as efficientnet\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score, precision_score, recall_score\n\nprint(\"Tensorflow version \" + tf.__version__)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-06-14T19:29:18.958161Z","iopub.execute_input":"2023-06-14T19:29:18.958439Z","iopub.status.idle":"2023-06-14T19:30:05.470710Z","shell.execute_reply.started":"2023-06-14T19:29:18.958413Z","shell.execute_reply":"2023-06-14T19:30:05.469784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n    if 'GPU' in tf.test.gpu_device_name():\n        print('Running on GPU', tf.test.gpu_device_name())\n    else:\n        print('Running on CPU')\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelif 'GPU' in tf.test.gpu_device_name():\n    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:05.472106Z","iopub.execute_input":"2023-06-14T19:30:05.472632Z","iopub.status.idle":"2023-06-14T19:30:14.507006Z","shell.execute_reply.started":"2023-06-14T19:30:05.472604Z","shell.execute_reply":"2023-06-14T19:30:14.503829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from shutil import rmtree\n\ntry:\n    rmtree(\"/kaggle/working/Neural-Networks-2023-Project\")\n    print(\"Removing previous project folder\")\n    del sys.modules['utils.DataLoad']\n    del DataLoad\n    del sys.modules['utils.DataVisualization']\nexcept:\n    print('No previous project folder found in working directory.')\n\n! git clone https://github.com/m-tarro/Neural-Networks-2023-Project.git\n\nsys.path.append('/kaggle/working/Neural-Networks-2023-Project/')\n\nfrom utils.DataLoad import DataLoad\nfrom utils.DataVisualization import *","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:14.509386Z","iopub.execute_input":"2023-06-14T19:30:14.510247Z","iopub.status.idle":"2023-06-14T19:30:16.885038Z","shell.execute_reply.started":"2023-06-14T19:30:14.510212Z","shell.execute_reply":"2023-06-14T19:30:16.883794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data exploration","metadata":{}},{"cell_type":"code","source":"class_counts = {}\n\nimage_size = 512\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\ndata_load = DataLoad(image_size=image_size, batch_size=BATCH_SIZE)\nds_explore = data_load.get_training_dataset(ordered=True, onehot=False, split=False)\n\n# Get the total number of iterations\ntotal_iterations = data_load.NUM_TRAINING_IMAGES\n\n# Use tqdm to create a progress bar\nfor _, label in tqdm(ds_explore.unbatch(), total=total_iterations, desc='Processing images'):\n    i = label.numpy()\n    if i not in class_counts:\n        # print(data_load.CLASSES[i])\n        class_counts[i] = 1\n    else:\n        class_counts[i] += 1\n        \n    total_iterations -= 1  # Decrement the total_iterations count\n\n    if total_iterations == 0:\n        break  # Exit the loop when all elements have been processed","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:16.886526Z","iopub.execute_input":"2023-06-14T19:30:16.886868Z","iopub.status.idle":"2023-06-14T19:30:32.132548Z","shell.execute_reply.started":"2023-06-14T19:30:16.886836Z","shell.execute_reply":"2023-06-14T19:30:32.131457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_weight_for_class(class_id):\n    counting = class_counts[class_id]\n    weight = 1 / counting\n    return weight\n\n#This is the dictionary to use in model fitting to further tweak it\nweight_per_class = {class_id: get_weight_for_class(class_id) for class_id in class_counts.keys()}\n\n#In order to use it, add \n#class_weight = weight_per_class \n#inside the fit function","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:32.134052Z","iopub.execute_input":"2023-06-14T19:30:32.134403Z","iopub.status.idle":"2023-06-14T19:30:32.140849Z","shell.execute_reply.started":"2023-06-14T19:30:32.134374Z","shell.execute_reply":"2023-06-14T19:30:32.139889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model to implement\n\nThe data will load to data_load based on chosen `IMAGE_SIZE` and `BATCH_SIZE`. Then the model has to be compiled within `strategy.scope()`, compiled with chosen `optimizer`, `loss`, and `metrics`.","metadata":{}},{"cell_type":"code","source":"# Specify the maximum amount of cropping and rotation (sampled randomly)\nmax_crop = 0.6\nmax_rotate = 20\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Function sampling random degrees for image rotation\ndef rand_degree():\n    lower = -max_rotate * (np.pi/180.0) # degrees -> radian\n    upper =  max_rotate * (np.pi/180.0) \n    return np.random.uniform(lower, upper), max_rotate\n\n# Our manual augmentation function\ndef manual_augment(image, label):\n    #data augmentation to prevent overfitting and to find more patterns.\n\n    # Image dimensions\n    height, width = image.shape[-3:-1]\n\n    # Crop image\n    crop = np.random.uniform(max_crop,1) # Sample crop size\n    box_top  = int(np.random.uniform(0,(1-crop)*height)) # Sample crop location\n    box_left = int(np.random.uniform(0,(1-crop)*width))\n\n    cropped = tf.image.crop_to_bounding_box(image, box_top, box_left, int(height*crop), int(width*crop)) # Crop image\n    image = tf.image.resize(cropped, (height, width), method='bilinear') # Resize to original image size\n\n    # Alter image\n    image = tf.image.random_flip_left_right(image)  # Flipping left-right makes sense due to flower variation\n    image = tf.image.random_saturation(image, 0, 3) # Random saturation makes sense due to growth cycles, lighting\n\n    # Rotate image\n    degree, max_rotate = rand_degree() # Sample angle\n\n    if np.abs(degree) > (max_rotate/6) * (np.pi/180.0): # If angle is big enough, rotate\n        image = tfa.image.rotate(image, degree, fill_mode='nearest')  # Rotation makes sense due to flower variation, foto angle\n\n\n    #image = tf.image.random_flip_up_down(image)    # Flipping up-down does not make sense because flowers don't grow that way\n    #image = tf.image.random_brightness(image, 0.1) \n\n    return image, label\n\ndef cutmixup__(image, label):\n\n    CutMixUp = augment.MixupAndCutmix(\n        mixup_alpha = 0.8,\n        cutmix_alpha = 0.5, # default 1.0\n        prob = 0.6, # default 1.0\n        switch_prob = 0.5,\n        label_smoothing = 0.1,\n        num_classes = 104\n    )\n    cutmix_images, cutmix_labels = CutMixUp(images=image, labels=label)\n        \n    image2 = tf.reshape(tf.stack(cutmix_images),(BATCH_SIZE,image_size,image_size,3))\n    label2 = tf.reshape(tf.stack(cutmix_labels),(BATCH_SIZE,len(data_load.CLASSES)))\n    return image2,label2\n\ndef cutmixup(batch_inputs: tf.data.Dataset, onehot=True):\n\n    CutMixUp = augment.MixupAndCutmix(\n        mixup_alpha = 0.8,\n        cutmix_alpha = 0.5, # default 1.0\n        prob = 0.6, # default 1.0\n        switch_prob = 0.5,\n        label_smoothing = 0.1,\n        num_classes = 104\n    )\n    cutmix_images, cutmix_labels = CutMixUp(images=batch_inputs[0], labels=batch_inputs[1])\n    if not onehot:\n        cutmix_labels = tf.argmax(cutmix_labels, axis=-1)\n    \n    return cutmix_images, cutmix_labels\n\ndef mixup(batch_inputs: tf.data.Dataset, onehot=True):\n\n    CutMixUp = augment.MixupAndCutmix(\n        mixup_alpha = 0.8,\n        cutmix_alpha = 0.0, # disable CutMix\n        prob = 0.6, # default 1.0\n        switch_prob = 0.0, # disable CutMix\n        label_smoothing = 0.1,\n        num_classes = 104\n    )\n    cutmix_images, cutmix_labels = CutMixUp(images=batch_inputs[0], labels=batch_inputs[1])\n    if not onehot:\n        cutmix_labels = tf.argmax(cutmix_labels, axis=-1)\n    \n    return cutmix_images, cutmix_labels\n\ndef cutmix(batch_inputs: tf.data.Dataset, onehot=True):\n\n    CutMixUp = augment.MixupAndCutmix(\n        mixup_alpha = 0.0, # disable MixUp\n        cutmix_alpha = 0.5, # default 1.0\n        prob = 0.6, # default 1.0\n        switch_prob = 0.5,\n        label_smoothing = 0.1,\n        num_classes = 104\n    )\n    cutmix_images, cutmix_labels = CutMixUp(images=batch_inputs[0], labels=batch_inputs[1])\n    if not onehot:\n        cutmix_labels = tf.argmax(cutmix_labels, axis=-1)\n    \n    return cutmix_images, cutmix_labels","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:32.142213Z","iopub.execute_input":"2023-06-14T19:30:32.142528Z","iopub.status.idle":"2023-06-14T19:30:32.168019Z","shell.execute_reply.started":"2023-06-14T19:30:32.142501Z","shell.execute_reply":"2023-06-14T19:30:32.167178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [image_size, image_size]\nEPOCHS = 30\nSTEPS_PER_EPOCH = data_load.TRAINING_STEPS_PER_EPOCH\n\nmodel_name = 'combination_densenet201'\nonehot = True\n\nds_train = data_load.get_training_dataset(image_augment=manual_augment, batch_augment=cutmixup__, onehot=onehot, split=False)\nds_valid = data_load.get_validation_dataset(onehot=onehot)\nds_test = data_load.get_test_dataset(ordered=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:32.169060Z","iopub.execute_input":"2023-06-14T19:30:32.169806Z","iopub.status.idle":"2023-06-14T19:30:35.247485Z","shell.execute_reply.started":"2023-06-14T19:30:32.169778Z","shell.execute_reply":"2023-06-14T19:30:35.246571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Learning rate","metadata":{}},{"cell_type":"code","source":"# define a fine-tuned schedule for the Learning Rate Scheduler \ndef exponential_lr(epoch,\n                  start_lr=0.00001,min_lr=0.00001,max_lr=0.00005,\n                  rampup_epochs = 5, sustain_epochs = 0,\n                  exp_decay = 0.8):  # original exp_decay = 0.8\n    def lr(epoch, start_lr, min_lr,max_lr,rampup_epochs,sustain_epochs,\n          exp_decay):\n        # linear increase from start to rampup_epochs\n        if epoch < rampup_epochs:\n            lr= ((max_lr-start_lr)/\n                rampup_epochs * epoch + start_lr)\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr \n        else:\n            lr = ((max_lr - min_lr)* exp_decay ** (epoch-rampup_epochs-sustain_epochs)\n                  + min_lr)\n            \n        return lr\n    return lr(epoch,start_lr,min_lr,max_lr,rampup_epochs,sustain_epochs,exp_decay)\n\n# set learning rate scheduler for callback\nlr_callback = tf.keras.callbacks.LearningRateScheduler(schedule=exponential_lr,verbose=True)\n\n# learning rate chart\n# epoch_rng = [i for i in range(EPOCHS)] \n# y = [exponential_lr(x) for x in epoch_rng]\n# plt.plot(epoch_rng,y)\n# plt.xlim(-1, EPOCHS)\n\n# print(\"Learning rate schedule: start = {:.3g}; peak = {:.3g}; end = {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:35.248658Z","iopub.execute_input":"2023-06-14T19:30:35.248954Z","iopub.status.idle":"2023-06-14T19:30:35.257512Z","shell.execute_reply.started":"2023-06-14T19:30:35.248929Z","shell.execute_reply":"2023-06-14T19:30:35.256772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model compiling","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n\n#     pretrained_model = efficientnet.EfficientNetB7(\n#              weights = 'noisy-student', \n#              include_top = False,\n#              input_shape = [*IMAGE_SIZE, 3])\n\n    pretrained_model = tf.keras.applications.DenseNet201(\n             weights = 'imagenet', \n             include_top = False,\n             input_shape = [*IMAGE_SIZE, 3])\n\n#     pretrained_model = tf.keras.applications.xception.Xception(\n#              weights = 'imagenet',\n#              include_top = False ,\n#              input_shape = [*IMAGE_SIZE, 3])\n\n    pretrained_model.trainable = True\n    \n    model = tf.keras.Sequential([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_model,\n        # ... attach a new head to act as a classifier.\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(len(data_load.CLASSES), activation='softmax')\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:35.260436Z","iopub.execute_input":"2023-06-14T19:30:35.260732Z","iopub.status.idle":"2023-06-14T19:31:43.209954Z","shell.execute_reply.started":"2023-06-14T19:30:35.260689Z","shell.execute_reply":"2023-06-14T19:31:43.208646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_measure = '' if onehot==True else 'sparse_'\n# sparse measures used when onehot is not applied to save resources\n\nmodel.compile(\n    optimizer='adam',\n    loss = 'categorical_crossentropy',\n    metrics=['categorical_accuracy'],\n)\n\nearly_stopping = callbacks.EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=5, # how many epochs to wait before stopping\n    restore_best_weights=True,\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:45:04.878767Z","iopub.execute_input":"2023-06-14T19:45:04.879181Z","iopub.status.idle":"2023-06-14T19:45:05.115399Z","shell.execute_reply.started":"2023-06-14T19:45:04.879151Z","shell.execute_reply":"2023-06-14T19:45:05.114246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback, early_stopping],\n    class_weight = weight_per_class #tuning11\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:45:06.874064Z","iopub.execute_input":"2023-06-14T19:45:06.874496Z","iopub.status.idle":"2023-06-14T19:55:34.824747Z","shell.execute_reply.started":"2023-06-14T19:45:06.874463Z","shell.execute_reply":"2023-06-14T19:55:34.822665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\n\ndisplay_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211\n)\ndisplay_training_curves(\n    history.history['categorical_accuracy'],\n    history.history['val_categorical_accuracy'],\n    'accuracy',\n    212\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.394362Z","iopub.status.idle":"2023-06-14T19:44:04.394739Z","shell.execute_reply.started":"2023-06-14T19:44:04.394545Z","shell.execute_reply":"2023-06-14T19:44:04.394562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save(f'history_{model_name}.npy',history.history)\nmodel.save(f'model_{model_name}.h5')","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.396361Z","iopub.status.idle":"2023-06-14T19:44:04.396723Z","shell.execute_reply.started":"2023-06-14T19:44:04.396532Z","shell.execute_reply":"2023-06-14T19:44:04.396547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion matrix","metadata":{}},{"cell_type":"code","source":"# print(f'Best model based on F1 score is {best_f1_model}')\n\n# Load validation dataset from DataLoad object\ncmdataset = data_load.get_validation_dataset(ordered=True, onehot=False)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\n# Get correct labels and model predictions\ncm_correct_labels = next(iter(labels_ds.batch(data_load.NUM_TRAINING_IMAGES))).numpy()\n\ncm_probabilities = model.predict(images_ds)\ncm_predictions = np.argmax(cm_probabilities, axis=-1)\n\n# Compute confusion matrix and normalize\nlabels = range(len(data_load.CLASSES))\ncmat = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\ncmat = (cmat.T / cmat.sum(axis=1)).T\n","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.397798Z","iopub.status.idle":"2023-06-14T19:44:04.398119Z","shell.execute_reply.started":"2023-06-14T19:44:04.397957Z","shell.execute_reply":"2023-06-14T19:44:04.397973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = f1_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nprecision = precision_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nrecall = recall_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\n\ndisplay_confusion_matrix(cmat, score, precision, recall)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.399975Z","iopub.status.idle":"2023-06-14T19:44:04.400371Z","shell.execute_reply.started":"2023-06-14T19:44:04.400164Z","shell.execute_reply":"2023-06-14T19:44:04.400182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visual validation","metadata":{}},{"cell_type":"code","source":"dataset = cmdataset.unbatch().batch(20)\nbatch = iter(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.401391Z","iopub.status.idle":"2023-06-14T19:44:04.401717Z","shell.execute_reply.started":"2023-06-14T19:44:04.401547Z","shell.execute_reply":"2023-06-14T19:44:04.401562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels = next(batch)\nprobabilities = model.predict(images)\npredictions = np.argmax(probabilities, axis=-1)\ndisplay_batch_of_images((images, labels), predictions)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.403225Z","iopub.status.idle":"2023-06-14T19:44:04.403565Z","shell.execute_reply.started":"2023-06-14T19:44:04.403385Z","shell.execute_reply":"2023-06-14T19:44:04.403401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions to submit","metadata":{}},{"cell_type":"code","source":"def gen_submission_csv(model, data_load=DataLoad(), model_name=None, verbose=False):\n    if not model_name:\n        print('This will generate a final submission.csv file')\n        filename = 'submission.csv'\n    else:\n        filename = f'submission_{model_name}.csv'\n    \n    print('Computing predictions...')\n    ds_test = data_load.get_test_dataset(ordered=True)\n    test_images_ds = ds_test.map(lambda image, idnum: image).batch(BATCH_SIZE)\n    probabilities = model.predict(test_images_ds, steps=data_load.TEST_STEPS_PER_EPOCH+1)\n    predictions = np.argmax(probabilities, axis=-1)\n    \n    print(f'Generating {filename} file...')\n    test_ids_ds = ds_test.map(lambda image, idnum: idnum)\n    test_ids = next(iter(test_ids_ds.batch(data_load.NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\n    \n    np.savetxt(filename, \n               np.rec.fromarrays([test_ids, predictions]), \n               fmt=['%s', '%d'], \n               delimiter=',', \n               header='id,label', \n               comments='')\n    if verbose:\n        print()\n        !head submission{model_name}.csv","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.404614Z","iopub.status.idle":"2023-06-14T19:44:04.404941Z","shell.execute_reply.started":"2023-06-14T19:44:04.404780Z","shell.execute_reply":"2023-06-14T19:44:04.404795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If submitting to the competition, model_name should be either ignored or None\n\ngen_submission_csv(model, data_load, model_name=None)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.405832Z","iopub.status.idle":"2023-06-14T19:44:04.406146Z","shell.execute_reply.started":"2023-06-14T19:44:04.405986Z","shell.execute_reply":"2023-06-14T19:44:04.406002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submitting","metadata":{}},{"cell_type":"markdown","source":"If you haven't already, create your own editable copy of this notebook by clicking on the Copy and Edit button in the top right corner. Then, submit to the competition by following these steps:\n\n1. Begin by clicking on the blue Save Version button in the top right corner of the window. This will generate a pop-up window.\n2. Ensure that the Save and Run All option is selected, and then click on the blue Save button.\n3. This generates a window in the bottom left corner of the notebook. After it has finished running, click on the number to the right of the Save Version button. This pulls up a list of versions on the right of the screen. Click on the ellipsis (...) to the right of the most recent version, and select Open in Viewer. This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n4. Click on the Output tab on the right of the screen. Then, click on the file you would like to submit, and click on the blue Submit button to submit your results to the leaderboard.\n\nYou have now successfully submitted to the competition!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}