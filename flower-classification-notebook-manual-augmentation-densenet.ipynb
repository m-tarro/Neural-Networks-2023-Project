{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Necessary imports","metadata":{}},{"cell_type":"code","source":"!pip install -U scikit-learn\n# !pip install bokeh\n\n!pip install tf-models-official\n!pip install -U tensorflow-addons==0.20.0\n# !pip install efficientnet","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:28:22.570491Z","iopub.execute_input":"2023-06-14T19:28:22.570850Z","iopub.status.idle":"2023-06-14T19:29:18.956072Z","shell.execute_reply.started":"2023-06-14T19:28:22.570816Z","shell.execute_reply":"2023-06-14T19:29:18.954995Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting scikit-learn\n  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/site-packages (from scikit-learn) (1.23.5)\nCollecting threadpoolctl>=2.0.0\n  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\nCollecting joblib>=1.1.1\n  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 KB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: threadpoolctl, joblib, scikit-learn\nSuccessfully installed joblib-1.2.0 scikit-learn-1.2.2 threadpoolctl-3.1.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0mCollecting tf-models-official\n  Downloading tf_models_official-2.12.0-py2.py3-none-any.whl (2.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting immutabledict\n  Downloading immutabledict-2.2.4-py3-none-any.whl (4.1 kB)\nCollecting tf-slim>=1.1.0\n  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.8/site-packages (from tf-models-official) (1.8.0)\nRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.8/site-packages (from tf-models-official) (0.13.0)\nRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/site-packages (from tf-models-official) (1.10.1)\nCollecting opencv-python-headless\n  Downloading opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.2 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting pycocotools\n  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/site-packages (from tf-models-official) (3.7.1)\nCollecting pyyaml<6.0,>=5.1\n  Downloading PyYAML-5.4.1-cp38-cp38-manylinux1_x86_64.whl (662 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.4/662.4 KB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/site-packages (from tf-models-official) (4.8.3)\nRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/site-packages (from tf-models-official) (1.23.5)\nRequirement already satisfied: six in /usr/local/lib/python3.8/site-packages (from tf-models-official) (1.16.0)\nCollecting py-cpuinfo>=3.3.0\n  Downloading py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\nCollecting sacrebleu\n  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting tensorflow-addons\n  Downloading tensorflow_addons-0.20.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (591 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m591.0/591.0 KB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 KB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting kaggle>=1.3.9\n  Downloading kaggle-1.5.13.tar.gz (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.8/site-packages (from tf-models-official) (9.5.0)\nCollecting Cython\n  Using cached Cython-0.29.35-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (2.0 MB)\nRequirement already satisfied: tensorflow~=2.12.0 in /usr/local/lib/python3.8/site-packages (from tf-models-official) (2.12.0)\nRequirement already satisfied: gin-config in /usr/local/lib/python3.8/site-packages (from tf-models-official) (0.5.0)\nRequirement already satisfied: oauth2client in /usr/local/lib/python3.8/site-packages (from tf-models-official) (4.1.3)\nRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.8/site-packages (from tf-models-official) (5.9.4)\nCollecting sentencepiece\n  Downloading sentencepiece-0.1.99-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tensorflow-text~=2.12.0 in /usr/local/lib/python3.8/site-packages (from tf-models-official) (2.12.0)\nRequirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.8/site-packages (from tf-models-official) (2.0.0)\nRequirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official) (3.0.1)\nRequirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.17.1)\nRequirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.1.0)\nRequirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.22.0)\nRequirement already satisfied: google-api-core<2dev,>=1.13.0 in /usr/local/lib/python3.8/site-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.34.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official) (2022.12.7)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official) (2.28.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official) (4.65.0)\nCollecting python-slugify\n  Downloading python_slugify-8.0.1-py2.py3-none-any.whl (9.7 kB)\nRequirement already satisfied: urllib3 in /usr/local/lib/python3.8/site-packages (from kaggle>=1.3.9->tf-models-official) (1.26.15)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/site-packages (from pandas>=0.22.0->tf-models-official) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.8/site-packages (from pandas>=0.22.0->tf-models-official) (2023.3)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (4.5.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (2.2.0)\nRequirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (2.12.0)\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (3.8.0)\nRequirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (2.12.1)\nRequirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (0.4.6)\nRequirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (23.3.3)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (1.6.3)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (1.14.1)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (1.53.0)\nRequirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (2.12.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (0.32.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (23.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (0.2.0)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (1.4.0)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (0.4.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (3.20.3)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (3.3.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (57.5.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/site-packages (from tensorflow~=2.12.0->tf-models-official) (16.0.0)\nRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.8/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.8)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/site-packages (from matplotlib->tf-models-official) (0.11.0)\nRequirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.8/site-packages (from matplotlib->tf-models-official) (5.12.0)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/site-packages (from matplotlib->tf-models-official) (4.39.3)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.8/site-packages (from matplotlib->tf-models-official) (3.0.9)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib->tf-models-official) (1.4.4)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.8/site-packages (from matplotlib->tf-models-official) (1.0.7)\nRequirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.8/site-packages (from oauth2client->tf-models-official) (0.4.8)\nRequirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.8/site-packages (from oauth2client->tf-models-official) (0.2.8)\nRequirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.8/site-packages (from oauth2client->tf-models-official) (4.9)\nCollecting portalocker\n  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.8/site-packages (from sacrebleu->tf-models-official) (0.9.0)\nCollecting colorama\n  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\nCollecting lxml\n  Downloading lxml-4.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting regex\n  Downloading regex-2023.6.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (772 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.3/772.3 KB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.8/site-packages (from seqeval->tf-models-official) (1.2.2)\nCollecting typeguard<3.0.0,>=2.7\n  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\nRequirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official) (1.12.0)\nRequirement already satisfied: click in /usr/local/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official) (8.1.3)\nRequirement already satisfied: promise in /usr/local/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official) (2.3)\nRequirement already satisfied: toml in /usr/local/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official) (0.10.2)\nRequirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/site-packages (from tensorflow-datasets->tf-models-official) (1.1.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow~=2.12.0->tf-models-official) (0.40.0)\nRequirement already satisfied: zipp in /usr/local/lib/python3.8/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->tf-models-official) (3.15.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/site-packages (from google-api-core<2dev,>=1.13.0->google-api-python-client>=1.6.7->tf-models-official) (1.59.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/site-packages (from google-auth>=1.4.1->google-api-python-client>=1.6.7->tf-models-official) (5.3.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/site-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/site-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.4)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/site-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (3.1.0)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (0.7.0)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (3.4.3)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (1.0.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (2.2.3)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (1.8.1)\nCollecting text-unidecode>=1.3\n  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (1.3.1)\nRequirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (6.1.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (2.1.2)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow~=2.12.0->tf-models-official) (3.2.2)\nBuilding wheels for collected packages: kaggle, pycocotools, seqeval\n  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.13-py3-none-any.whl size=77734 sha256=f8da1133d034ac0213f5a14482e4a9b04760efe1a6581e7a12301d1230b17bf6\n  Stored in directory: /root/.cache/pip/wheels/e6/8e/67/e07554a720a493dc6b39b30488590ba92ed45448ad0134d253\n  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp38-cp38-linux_x86_64.whl size=408134 sha256=1ead5ab66d08dfd2b0438425ac2ad1334d9a85888f47e9843b11cccf7a926bbd\n  Stored in directory: /root/.cache/pip/wheels/3e/08/ac/58126fe59992032701437336493f6132e1b72381a62d00b595\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=b1c05302d0e3e9fa872b89f8e165a3767a0c6ae3e3e34c33914f938a7ae0b677\n  Stored in directory: /root/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\nSuccessfully built kaggle pycocotools seqeval\nInstalling collected packages: text-unidecode, sentencepiece, py-cpuinfo, typeguard, tf-slim, tensorflow-model-optimization, regex, pyyaml, python-slugify, portalocker, opencv-python-headless, lxml, immutabledict, Cython, colorama, tensorflow-addons, sacrebleu, kaggle, seqeval, pycocotools, tf-models-official\n  Attempting uninstall: pyyaml\n    Found existing installation: PyYAML 6.0\n    Uninstalling PyYAML-6.0:\n      Successfully uninstalled PyYAML-6.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntreex 0.6.12 requires PyYAML>=6.0, but you have pyyaml 5.4.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed Cython-0.29.35 colorama-0.4.6 immutabledict-2.2.4 kaggle-1.5.13 lxml-4.9.2 opencv-python-headless-4.7.0.72 portalocker-2.7.0 py-cpuinfo-9.0.0 pycocotools-2.0.6 python-slugify-8.0.1 pyyaml-5.4.1 regex-2023.6.3 sacrebleu-2.3.1 sentencepiece-0.1.99 seqeval-1.2.2 tensorflow-addons-0.20.0 tensorflow-model-optimization-0.7.5 text-unidecode-1.3 tf-models-official-2.12.0 tf-slim-1.1.0 typeguard-2.13.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: tensorflow-addons==0.20.0 in /usr/local/lib/python3.8/site-packages (0.20.0)\nRequirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.8/site-packages (from tensorflow-addons==0.20.0) (2.13.3)\nRequirement already satisfied: packaging in /usr/local/lib/python3.8/site-packages (from tensorflow-addons==0.20.0) (23.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\nYou should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import math, re, os, sys\nimport numpy as np\nimport pandas as pd\nfrom itertools import islice\nfrom matplotlib import pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom tqdm import tqdm\n\n# from bokeh.plotting import figure, show, save\n# from bokeh.models import HoverTool, LinearColorMapper, ColumnDataSource\n# from bokeh.io import output_notebook\n# from bokeh.transform import linear_cmap\n\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom tensorflow.keras import layers, callbacks\nfrom tensorflow_models.vision import augment\n# import efficientnet.tfkeras as efficientnet\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score, precision_score, recall_score\n\nprint(\"Tensorflow version \" + tf.__version__)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-06-14T19:29:18.958161Z","iopub.execute_input":"2023-06-14T19:29:18.958439Z","iopub.status.idle":"2023-06-14T19:30:05.470710Z","shell.execute_reply.started":"2023-06-14T19:29:18.958413Z","shell.execute_reply":"2023-06-14T19:30:05.469784Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"D0614 19:29:52.461349638      14 config.cc:119]                        gRPC EXPERIMENT tcp_frame_size_tuning               OFF (default:OFF)\nD0614 19:29:52.461396560      14 config.cc:119]                        gRPC EXPERIMENT tcp_rcv_lowat                       OFF (default:OFF)\nD0614 19:29:52.461400305      14 config.cc:119]                        gRPC EXPERIMENT peer_state_based_framing            OFF (default:OFF)\nD0614 19:29:52.461402988      14 config.cc:119]                        gRPC EXPERIMENT flow_control_fixes                  ON  (default:ON)\nD0614 19:29:52.461405116      14 config.cc:119]                        gRPC EXPERIMENT memory_pressure_controller          OFF (default:OFF)\nD0614 19:29:52.461407520      14 config.cc:119]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size OFF (default:OFF)\nD0614 19:29:52.461410312      14 config.cc:119]                        gRPC EXPERIMENT new_hpack_huffman_decoder           ON  (default:ON)\nD0614 19:29:52.461412477      14 config.cc:119]                        gRPC EXPERIMENT event_engine_client                 OFF (default:OFF)\nD0614 19:29:52.461414544      14 config.cc:119]                        gRPC EXPERIMENT monitoring_experiment               ON  (default:ON)\nD0614 19:29:52.461416806      14 config.cc:119]                        gRPC EXPERIMENT promise_based_client_call           OFF (default:OFF)\nD0614 19:29:52.461418835      14 config.cc:119]                        gRPC EXPERIMENT free_large_allocator                OFF (default:OFF)\nD0614 19:29:52.461420973      14 config.cc:119]                        gRPC EXPERIMENT promise_based_server_call           OFF (default:OFF)\nD0614 19:29:52.461423067      14 config.cc:119]                        gRPC EXPERIMENT transport_supplies_client_latency   OFF (default:OFF)\nD0614 19:29:52.461435129      14 config.cc:119]                        gRPC EXPERIMENT event_engine_listener               OFF (default:OFF)\nI0614 19:29:52.463905785      14 ev_epoll1_linux.cc:122]               grpc epoll fd: 62\nD0614 19:29:52.475764987      14 ev_posix.cc:144]                      Using polling engine: epoll1\nD0614 19:29:52.475803949      14 dns_resolver_ares.cc:822]             Using ares dns resolver\nD0614 19:29:52.476237986      14 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0614 19:29:52.476248839      14 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0614 19:29:52.476252474      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0614 19:29:52.476255415      14 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0614 19:29:52.476258452      14 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0614 19:29:52.476261426      14 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin_experimental\"\nD0614 19:29:52.476268057      14 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0614 19:29:52.476282407      14 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0614 19:29:52.476305193      14 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0614 19:29:52.476317622      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0614 19:29:52.476320758      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0614 19:29:52.476323739      14 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0614 19:29:52.476328964      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_resolver_experimental\"\nD0614 19:29:52.476331954      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0614 19:29:52.476334776      14 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0614 19:29:52.476338736      14 certificate_provider_registry.cc:35]  registering certificate provider factory for \"file_watcher\"\nI0614 19:29:52.478882136      14 socket_utils_common_posix.cc:408]     Disabling AF_INET6 sockets because ::1 is not available.\nI0614 19:29:52.495132120     503 socket_utils_common_posix.cc:337]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0614 19:29:52.504051085      14 oauth2_credentials.cc:236]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2023-06-14T19:29:52.504034501+00:00\"}\n","output_type":"stream"},{"name":"stdout","text":"Tensorflow version 2.12.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Detect TPU, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n    if 'GPU' in tf.test.gpu_device_name():\n        print('Running on GPU', tf.test.gpu_device_name())\n    else:\n        print('Running on CPU')\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelif 'GPU' in tf.test.gpu_device_name():\n    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:05.472106Z","iopub.execute_input":"2023-06-14T19:30:05.472632Z","iopub.status.idle":"2023-06-14T19:30:14.507006Z","shell.execute_reply.started":"2023-06-14T19:30:05.472604Z","shell.execute_reply":"2023-06-14T19:30:14.503829Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Running on TPU  \nINFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Finished initializing TPU system.\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:Found TPU system:\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Workers: 1\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"},{"name":"stdout","text":"REPLICAS:  8\n","output_type":"stream"}]},{"cell_type":"code","source":"from shutil import rmtree\n\ntry:\n    rmtree(\"/kaggle/working/Neural-Networks-2023-Project\")\n    print(\"Removing previous project folder\")\n    del sys.modules['utils.DataLoad']\n    del DataLoad\n    del sys.modules['utils.DataVisualization']\nexcept:\n    print('No previous project folder found in working directory.')\n\n! git clone https://github.com/m-tarro/Neural-Networks-2023-Project.git\n\nsys.path.append('/kaggle/working/Neural-Networks-2023-Project/')\n\nfrom utils.DataLoad import DataLoad\nfrom utils.DataVisualization import *","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:14.509386Z","iopub.execute_input":"2023-06-14T19:30:14.510247Z","iopub.status.idle":"2023-06-14T19:30:16.885038Z","shell.execute_reply.started":"2023-06-14T19:30:14.510212Z","shell.execute_reply":"2023-06-14T19:30:16.883794Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"No previous project folder found in working directory.\nCloning into 'Neural-Networks-2023-Project'...\nremote: Enumerating objects: 219, done.\u001b[K\nremote: Counting objects: 100% (21/21), done.\u001b[K\nremote: Compressing objects: 100% (21/21), done.\u001b[K\nremote: Total 219 (delta 8), reused 0 (delta 0), pack-reused 198\u001b[K\nReceiving objects: 100% (219/219), 38.71 MiB | 46.96 MiB/s, done.\nResolving deltas: 100% (100/100), done.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Data exploration","metadata":{}},{"cell_type":"code","source":"class_counts = {}\n\nimage_size = 512\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\n\ndata_load = DataLoad(image_size=image_size, batch_size=BATCH_SIZE)\nds_explore = data_load.get_training_dataset(ordered=True, onehot=False, split=False)\n\n# Get the total number of iterations\ntotal_iterations = data_load.NUM_TRAINING_IMAGES\n\n# Use tqdm to create a progress bar\nfor _, label in tqdm(ds_explore.unbatch(), total=total_iterations, desc='Processing images'):\n    i = label.numpy()\n    if i not in class_counts:\n        # print(data_load.CLASSES[i])\n        class_counts[i] = 1\n    else:\n        class_counts[i] += 1\n        \n    total_iterations -= 1  # Decrement the total_iterations count\n\n    if total_iterations == 0:\n        break  # Exit the loop when all elements have been processed","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:16.886526Z","iopub.execute_input":"2023-06-14T19:30:16.886868Z","iopub.status.idle":"2023-06-14T19:30:32.132548Z","shell.execute_reply.started":"2023-06-14T19:30:16.886836Z","shell.execute_reply":"2023-06-14T19:30:32.131457Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Processing images: 100%|█████████▉| 12752/12753 [00:14<00:00, 852.56it/s] \n","output_type":"stream"}]},{"cell_type":"code","source":"def get_weight_for_class(class_id):\n    counting = class_counts[class_id]\n    weight = 1 / counting\n    return weight\n\n#This is the dictionary to use in model fitting to further tweak it\nweight_per_class = {class_id: get_weight_for_class(class_id) for class_id in class_counts.keys()}\n\n#In order to use it, add \n#class_weight = weight_per_class \n#inside the fit function","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:32.134052Z","iopub.execute_input":"2023-06-14T19:30:32.134403Z","iopub.status.idle":"2023-06-14T19:30:32.140849Z","shell.execute_reply.started":"2023-06-14T19:30:32.134374Z","shell.execute_reply":"2023-06-14T19:30:32.139889Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Model to implement\n\nThe data will load to data_load based on chosen `IMAGE_SIZE` and `BATCH_SIZE`. Then the model has to be compiled within `strategy.scope()`, compiled with chosen `optimizer`, `loss`, and `metrics`.","metadata":{}},{"cell_type":"code","source":"# Specify the maximum amount of cropping and rotation (sampled randomly)\nmax_crop = 0.6\nmax_rotate = 20\nAUTO = tf.data.experimental.AUTOTUNE\n\n# Function sampling random degrees for image rotation\ndef rand_degree():\n    lower = -max_rotate * (np.pi/180.0) # degrees -> radian\n    upper =  max_rotate * (np.pi/180.0) \n    return np.random.uniform(lower, upper), max_rotate\n\n# Our manual augmentation function\ndef manual_augment(image, label):\n    #data augmentation to prevent overfitting and to find more patterns.\n\n    # Image dimensions\n    height, width = image.shape[-3:-1]\n\n    # Crop image\n    crop = np.random.uniform(max_crop,1) # Sample crop size\n    box_top  = int(np.random.uniform(0,(1-crop)*height)) # Sample crop location\n    box_left = int(np.random.uniform(0,(1-crop)*width))\n\n    cropped = tf.image.crop_to_bounding_box(image, box_top, box_left, int(height*crop), int(width*crop)) # Crop image\n    image = tf.image.resize(cropped, (height, width), method='bilinear') # Resize to original image size\n\n    # Alter image\n    image = tf.image.random_flip_left_right(image)  # Flipping left-right makes sense due to flower variation\n    image = tf.image.random_saturation(image, 0, 3) # Random saturation makes sense due to growth cycles, lighting\n\n    # Rotate image\n    degree, max_rotate = rand_degree() # Sample angle\n\n    if np.abs(degree) > (max_rotate/6) * (np.pi/180.0): # If angle is big enough, rotate\n        image = tfa.image.rotate(image, degree, fill_mode='nearest')  # Rotation makes sense due to flower variation, foto angle\n\n\n    #image = tf.image.random_flip_up_down(image)    # Flipping up-down does not make sense because flowers don't grow that way\n    #image = tf.image.random_brightness(image, 0.1) \n\n    return image, label\n\ndef cutmixup__(image, label):\n\n    CutMixUp = augment.MixupAndCutmix(\n        mixup_alpha = 0.8,\n        cutmix_alpha = 0.5, # default 1.0\n        prob = 0.6, # default 1.0\n        switch_prob = 0.5,\n        label_smoothing = 0.1,\n        num_classes = 104\n    )\n    cutmix_images, cutmix_labels = CutMixUp(images=image, labels=label)\n        \n    image2 = tf.reshape(tf.stack(cutmix_images),(BATCH_SIZE,image_size,image_size,3))\n    label2 = tf.reshape(tf.stack(cutmix_labels),(BATCH_SIZE,len(data_load.CLASSES)))\n    return image2,label2\n\ndef cutmixup(batch_inputs: tf.data.Dataset, onehot=True):\n\n    CutMixUp = augment.MixupAndCutmix(\n        mixup_alpha = 0.8,\n        cutmix_alpha = 0.5, # default 1.0\n        prob = 0.6, # default 1.0\n        switch_prob = 0.5,\n        label_smoothing = 0.1,\n        num_classes = 104\n    )\n    cutmix_images, cutmix_labels = CutMixUp(images=batch_inputs[0], labels=batch_inputs[1])\n    if not onehot:\n        cutmix_labels = tf.argmax(cutmix_labels, axis=-1)\n    \n    return cutmix_images, cutmix_labels\n\ndef mixup(batch_inputs: tf.data.Dataset, onehot=True):\n\n    CutMixUp = augment.MixupAndCutmix(\n        mixup_alpha = 0.8,\n        cutmix_alpha = 0.0, # disable CutMix\n        prob = 0.6, # default 1.0\n        switch_prob = 0.0, # disable CutMix\n        label_smoothing = 0.1,\n        num_classes = 104\n    )\n    cutmix_images, cutmix_labels = CutMixUp(images=batch_inputs[0], labels=batch_inputs[1])\n    if not onehot:\n        cutmix_labels = tf.argmax(cutmix_labels, axis=-1)\n    \n    return cutmix_images, cutmix_labels\n\ndef cutmix(batch_inputs: tf.data.Dataset, onehot=True):\n\n    CutMixUp = augment.MixupAndCutmix(\n        mixup_alpha = 0.0, # disable MixUp\n        cutmix_alpha = 0.5, # default 1.0\n        prob = 0.6, # default 1.0\n        switch_prob = 0.5,\n        label_smoothing = 0.1,\n        num_classes = 104\n    )\n    cutmix_images, cutmix_labels = CutMixUp(images=batch_inputs[0], labels=batch_inputs[1])\n    if not onehot:\n        cutmix_labels = tf.argmax(cutmix_labels, axis=-1)\n    \n    return cutmix_images, cutmix_labels","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:32.142213Z","iopub.execute_input":"2023-06-14T19:30:32.142528Z","iopub.status.idle":"2023-06-14T19:30:32.168019Z","shell.execute_reply.started":"2023-06-14T19:30:32.142501Z","shell.execute_reply":"2023-06-14T19:30:32.167178Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [image_size, image_size]\nEPOCHS = 30\nSTEPS_PER_EPOCH = data_load.TRAINING_STEPS_PER_EPOCH\n\nmodel_name = 'combination_densenet201'\nonehot = True\n\nds_train = data_load.get_training_dataset(image_augment=manual_augment, batch_augment=cutmixup__, onehot=onehot, split=False)\nds_valid = data_load.get_validation_dataset(onehot=onehot)\nds_test = data_load.get_test_dataset(ordered=True)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:32.169060Z","iopub.execute_input":"2023-06-14T19:30:32.169806Z","iopub.status.idle":"2023-06-14T19:30:35.247485Z","shell.execute_reply.started":"2023-06-14T19:30:32.169778Z","shell.execute_reply":"2023-06-14T19:30:35.246571Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nUse fn_output_signature instead\n","output_type":"stream"},{"name":"stderr","text":"WARNING:tensorflow:From /usr/local/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\nInstructions for updating:\nUse fn_output_signature instead\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Learning rate","metadata":{}},{"cell_type":"code","source":"# define a fine-tuned schedule for the Learning Rate Scheduler \ndef exponential_lr(epoch,\n                  start_lr=0.00001,min_lr=0.00001,max_lr=0.00005,\n                  rampup_epochs = 5, sustain_epochs = 0,\n                  exp_decay = 0.8):  # original exp_decay = 0.8\n    def lr(epoch, start_lr, min_lr,max_lr,rampup_epochs,sustain_epochs,\n          exp_decay):\n        # linear increase from start to rampup_epochs\n        if epoch < rampup_epochs:\n            lr= ((max_lr-start_lr)/\n                rampup_epochs * epoch + start_lr)\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr \n        else:\n            lr = ((max_lr - min_lr)* exp_decay ** (epoch-rampup_epochs-sustain_epochs)\n                  + min_lr)\n            \n        return lr\n    return lr(epoch,start_lr,min_lr,max_lr,rampup_epochs,sustain_epochs,exp_decay)\n\n# set learning rate scheduler for callback\nlr_callback = tf.keras.callbacks.LearningRateScheduler(schedule=exponential_lr,verbose=True)\n\n# learning rate chart\n# epoch_rng = [i for i in range(EPOCHS)] \n# y = [exponential_lr(x) for x in epoch_rng]\n# plt.plot(epoch_rng,y)\n# plt.xlim(-1, EPOCHS)\n\n# print(\"Learning rate schedule: start = {:.3g}; peak = {:.3g}; end = {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:35.248658Z","iopub.execute_input":"2023-06-14T19:30:35.248954Z","iopub.status.idle":"2023-06-14T19:30:35.257512Z","shell.execute_reply.started":"2023-06-14T19:30:35.248929Z","shell.execute_reply":"2023-06-14T19:30:35.256772Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Model compiling","metadata":{}},{"cell_type":"code","source":"with strategy.scope():\n\n#     pretrained_model = efficientnet.EfficientNetB7(\n#              weights = 'noisy-student', \n#              include_top = False,\n#              input_shape = [*IMAGE_SIZE, 3])\n\n    pretrained_model = tf.keras.applications.DenseNet201(\n             weights = 'imagenet', \n             include_top = False,\n             input_shape = [*IMAGE_SIZE, 3])\n\n#     pretrained_model = tf.keras.applications.xception.Xception(\n#              weights = 'imagenet',\n#              include_top = False ,\n#              input_shape = [*IMAGE_SIZE, 3])\n\n    pretrained_model.trainable = True\n    \n    model = tf.keras.Sequential([\n        # To a base pretrained on ImageNet to extract features from images...\n        pretrained_model,\n        # ... attach a new head to act as a classifier.\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(len(data_load.CLASSES), activation='softmax')\n    ])","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:30:35.260436Z","iopub.execute_input":"2023-06-14T19:30:35.260732Z","iopub.status.idle":"2023-06-14T19:31:43.209954Z","shell.execute_reply.started":"2023-06-14T19:30:35.260689Z","shell.execute_reply":"2023-06-14T19:31:43.208646Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n74836368/74836368 [==============================] - 1s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"loss_measure = '' if onehot==True else 'sparse_'\n# sparse measures used when onehot is not applied to save resources\n\nmodel.compile(\n    optimizer='adam',\n    loss = 'categorical_crossentropy',\n    metrics=['categorical_accuracy'],\n)\n\nearly_stopping = callbacks.EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.001, # minimium amount of change to count as an improvement\n    patience=5, # how many epochs to wait before stopping\n    restore_best_weights=True,\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:45:04.878767Z","iopub.execute_input":"2023-06-14T19:45:04.879181Z","iopub.status.idle":"2023-06-14T19:45:05.115399Z","shell.execute_reply.started":"2023-06-14T19:45:04.879151Z","shell.execute_reply":"2023-06-14T19:45:05.114246Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n densenet201 (Functional)    (None, 16, 16, 1920)      18321984  \n                                                                 \n global_average_pooling2d (G  (None, 1920)             0         \n lobalAveragePooling2D)                                          \n                                                                 \n dense (Dense)               (None, 104)               199784    \n                                                                 \n=================================================================\nTotal params: 18,521,768\nTrainable params: 18,292,712\nNon-trainable params: 229,056\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"history = model.fit(\n    ds_train,\n    validation_data=ds_valid,\n    epochs=EPOCHS,\n    steps_per_epoch=STEPS_PER_EPOCH,\n    callbacks=[lr_callback, early_stopping],\n    class_weight = weight_per_class #tuning11\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:45:06.874064Z","iopub.execute_input":"2023-06-14T19:45:06.874496Z","iopub.status.idle":"2023-06-14T19:55:34.824747Z","shell.execute_reply.started":"2023-06-14T19:45:06.874463Z","shell.execute_reply":"2023-06-14T19:55:34.822665Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"\nEpoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2023-06-14 19:46:30.476586: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-06-14 19:46:33.410962: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"99/99 [==============================] - ETA: 0s - loss: 0.0201 - categorical_accuracy: 0.5874","output_type":"stream"},{"name":"stderr","text":"2023-06-14 19:48:30.301972: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n2023-06-14 19:48:30.880074: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"99/99 [==============================] - 221s 1s/step - loss: 0.0201 - categorical_accuracy: 0.5874 - val_loss: 2.3362 - val_categorical_accuracy: 0.4275 - lr: 0.0010\n\nEpoch 2: LearningRateScheduler setting learning rate to 0.0008100000379979611.\nEpoch 2/30\n99/99 [==============================] - 98s 997ms/step - loss: 0.0177 - categorical_accuracy: 0.6611 - val_loss: 1.5551 - val_categorical_accuracy: 0.6371 - lr: 8.1000e-04\n\nEpoch 3: LearningRateScheduler setting learning rate to 0.0005060000335611404.\nEpoch 3/30\n99/99 [==============================] - 93s 939ms/step - loss: 0.0157 - categorical_accuracy: 0.7415 - val_loss: 0.8543 - val_categorical_accuracy: 0.8192 - lr: 5.0600e-04\n\nEpoch 4: LearningRateScheduler setting learning rate to 0.00023240000449121004.\nEpoch 4/30\n99/99 [==============================] - 94s 951ms/step - loss: 0.0155 - categorical_accuracy: 0.7522 - val_loss: 0.6914 - val_categorical_accuracy: 0.8599 - lr: 2.3240e-04\n\nEpoch 5: LearningRateScheduler setting learning rate to 8.648000176530332e-05.\nEpoch 5/30\n99/99 [==============================] - 96s 971ms/step - loss: 0.0143 - categorical_accuracy: 0.8084 - val_loss: 0.6765 - val_categorical_accuracy: 0.8758 - lr: 8.6480e-05\n\nEpoch 6: LearningRateScheduler setting learning rate to 5e-05.\nEpoch 6/30\n29/99 [=======>......................] - ETA: 56s - loss: 0.0142 - categorical_accuracy: 0.7947","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mds_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mds_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEPS_PER_EPOCH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlr_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweight_per_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#tuning11\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n","File \u001b[0;32m/usr/local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"%matplotlib inline\n\ndisplay_training_curves(\n    history.history['loss'],\n    history.history['val_loss'],\n    'loss',\n    211\n)\ndisplay_training_curves(\n    history.history['categorical_accuracy'],\n    history.history['val_categorical_accuracy'],\n    'accuracy',\n    212\n)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.394362Z","iopub.status.idle":"2023-06-14T19:44:04.394739Z","shell.execute_reply.started":"2023-06-14T19:44:04.394545Z","shell.execute_reply":"2023-06-14T19:44:04.394562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save(f'history_{model_name}.npy',history.history)\nmodel.save(f'model_{model_name}.h5')","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.396361Z","iopub.status.idle":"2023-06-14T19:44:04.396723Z","shell.execute_reply.started":"2023-06-14T19:44:04.396532Z","shell.execute_reply":"2023-06-14T19:44:04.396547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Confusion matrix","metadata":{}},{"cell_type":"code","source":"# print(f'Best model based on F1 score is {best_f1_model}')\n\n# Load validation dataset from DataLoad object\ncmdataset = data_load.get_validation_dataset(ordered=True, onehot=False)\nimages_ds = cmdataset.map(lambda image, label: image)\nlabels_ds = cmdataset.map(lambda image, label: label).unbatch()\n\n# Get correct labels and model predictions\ncm_correct_labels = next(iter(labels_ds.batch(data_load.NUM_TRAINING_IMAGES))).numpy()\n\ncm_probabilities = model.predict(images_ds)\ncm_predictions = np.argmax(cm_probabilities, axis=-1)\n\n# Compute confusion matrix and normalize\nlabels = range(len(data_load.CLASSES))\ncmat = confusion_matrix(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n)\ncmat = (cmat.T / cmat.sum(axis=1)).T\n","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.397798Z","iopub.status.idle":"2023-06-14T19:44:04.398119Z","shell.execute_reply.started":"2023-06-14T19:44:04.397957Z","shell.execute_reply":"2023-06-14T19:44:04.397973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = f1_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nprecision = precision_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\nrecall = recall_score(\n    cm_correct_labels,\n    cm_predictions,\n    labels=labels,\n    average='macro',\n)\n\ndisplay_confusion_matrix(cmat, score, precision, recall)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.399975Z","iopub.status.idle":"2023-06-14T19:44:04.400371Z","shell.execute_reply.started":"2023-06-14T19:44:04.400164Z","shell.execute_reply":"2023-06-14T19:44:04.400182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visual validation","metadata":{}},{"cell_type":"code","source":"dataset = cmdataset.unbatch().batch(20)\nbatch = iter(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.401391Z","iopub.status.idle":"2023-06-14T19:44:04.401717Z","shell.execute_reply.started":"2023-06-14T19:44:04.401547Z","shell.execute_reply":"2023-06-14T19:44:04.401562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images, labels = next(batch)\nprobabilities = model.predict(images)\npredictions = np.argmax(probabilities, axis=-1)\ndisplay_batch_of_images((images, labels), predictions)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.403225Z","iopub.status.idle":"2023-06-14T19:44:04.403565Z","shell.execute_reply.started":"2023-06-14T19:44:04.403385Z","shell.execute_reply":"2023-06-14T19:44:04.403401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions to submit","metadata":{}},{"cell_type":"code","source":"def gen_submission_csv(model, data_load=DataLoad(), model_name=None, verbose=False):\n    if not model_name:\n        print('This will generate a final submission.csv file')\n        filename = 'submission.csv'\n    else:\n        filename = f'submission_{model_name}.csv'\n    \n    print('Computing predictions...')\n    ds_test = data_load.get_test_dataset(ordered=True)\n    test_images_ds = ds_test.map(lambda image, idnum: image).batch(BATCH_SIZE)\n    probabilities = model.predict(test_images_ds, steps=data_load.TEST_STEPS_PER_EPOCH+1)\n    predictions = np.argmax(probabilities, axis=-1)\n    \n    print(f'Generating {filename} file...')\n    test_ids_ds = ds_test.map(lambda image, idnum: idnum)\n    test_ids = next(iter(test_ids_ds.batch(data_load.NUM_TEST_IMAGES))).numpy().astype('U') # all in one batch\n    \n    np.savetxt(filename, \n               np.rec.fromarrays([test_ids, predictions]), \n               fmt=['%s', '%d'], \n               delimiter=',', \n               header='id,label', \n               comments='')\n    if verbose:\n        print()\n        !head submission{model_name}.csv","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.404614Z","iopub.status.idle":"2023-06-14T19:44:04.404941Z","shell.execute_reply.started":"2023-06-14T19:44:04.404780Z","shell.execute_reply":"2023-06-14T19:44:04.404795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If submitting to the competition, model_name should be either ignored or None\n\ngen_submission_csv(model, data_load, model_name=None)","metadata":{"execution":{"iopub.status.busy":"2023-06-14T19:44:04.405832Z","iopub.status.idle":"2023-06-14T19:44:04.406146Z","shell.execute_reply.started":"2023-06-14T19:44:04.405986Z","shell.execute_reply":"2023-06-14T19:44:04.406002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submitting","metadata":{}},{"cell_type":"markdown","source":"If you haven't already, create your own editable copy of this notebook by clicking on the Copy and Edit button in the top right corner. Then, submit to the competition by following these steps:\n\n1. Begin by clicking on the blue Save Version button in the top right corner of the window. This will generate a pop-up window.\n2. Ensure that the Save and Run All option is selected, and then click on the blue Save button.\n3. This generates a window in the bottom left corner of the notebook. After it has finished running, click on the number to the right of the Save Version button. This pulls up a list of versions on the right of the screen. Click on the ellipsis (...) to the right of the most recent version, and select Open in Viewer. This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n4. Click on the Output tab on the right of the screen. Then, click on the file you would like to submit, and click on the blue Submit button to submit your results to the leaderboard.\n\nYou have now successfully submitted to the competition!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}